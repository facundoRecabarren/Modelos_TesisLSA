{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de dataframe/parquet con datos de todos los videos\n",
    "dataframe = pd.read_parquet('../01_datos/00_raw/raw_parquet')\n",
    "\n",
    "\"\"\" \n",
    "    ARMADO DE COLUMNAS PARA LECTURA DE DATAFRAME \n",
    "    Columnas numericas del 0 a 1085 representando la cantidad de puntos totales.\n",
    "\"\"\"\n",
    "columnsToRead = [str(i) for i in range(1086)]\n",
    "columnsToRead.append('sign')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A TENER EN CUENTA:\n",
    "\n",
    "<span style=\"color:red\">\n",
    "CAMBIAR EL ORDEN DE LAS PALABRAS EN ALGUNA DE LAS 2 LISTAS VA A LLEVAR A UNA LECTURA INCORRECTA DE LOS DATOS \n",
    "\n",
    "EN EL PARQUET COMPLETO ORIGINAL SI SE REALIZA UN CAMBIO (en el orden en que se almacenaron las palabras) ESTE DEBE REALIZARSE SOBRE LAS DEMAS NOTEBOOKs DE\n",
    "\n",
    "LECTURA Y CREACION DE PARQUETS YA SEA SOBRE EL ORIGINAL O LOS DE MUESTREO\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNS_LIST = ['nacer','comida','brillante','mujer', 'hijo', 'hombre', 'lejos', 'aprender', 'espumadera','amargo','leche','Uruguay','pais','donde','ninguno','nombre','perfume','sordo','comprar','encontrar', 'nave espacial']\n",
    "\n",
    "# se toma la lista original de señas ya que estas en el orden en que se encuentran, su indice representa correctamente el nombre del video original\n",
    "FULL_SIGNS_LIST = ['opaco', 'rojo', 'verde', 'amarillo', 'brillante', 'celeste', 'colores', 'rosa', 'mujer', 'enemigo', 'hijo', 'hombre', 'lejos','cajón','nacer','aprender','llamar','espumadera','amargo','dulce','leche','agua','comida','Argentina','Uruguay','pais','donde','apellido','burla','cumpleanos','desayuno','foto','hambre','mapa','moneda','musica','nave espacial','ninguno','nombre','paciencia','perfume','sordo','trampa','arroz','asado','caramelo','chicle','fideos','yogurt','aceptar','agradecer','apagar','aparecer','aterrizar','atrapar','ayudar','bailar','bañarse','comprar','copiar','correr','darse cuenta','dar','encontrar']\n",
    "\n",
    "NUMBER_OF_PERSONS = 10\n",
    "NUMBER_OF_VIDEOS_PER_PERSON = 5\n",
    "AMOUNT_OF_FRAMES = 10\n",
    "# semilla para la generacion de numero aleatorios en la eleccion de frames\n",
    "RANDOM_SEED = 48"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ACTIVACION/DESACTIVACION DE CARA y CANTIDAD DE FRAMES\n",
    "La variable \"useFacePoints\" añadirá las columnas necesarias para los puntos faciales que serán añadidos en el parquet a construir.\n",
    "La variable \"amount_of_frames\" aumentará las cantidad de columnas necesarias, en este caso, cuantos frames se tomaran de cada video para construir el parquet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_columns = []\n",
    "\n",
    "FACE_POINTS = 468\n",
    "POSE_POINT_INDEXES = [k for k in range(23)] #de los 33 puntos solo tomamos los hombros, brazos, cabeza (SIN CINTURA debido a los videos del set de datos)\n",
    "LEFT_HAND_POINTS = 21\n",
    "RIGHT_HAND_POINTS = 21\n",
    "\n",
    "# CAMBIAR ESTE BOOLEANO PARA TOMAR PUNTOS FACIALES O NO (se tomarán CEJAS y BOCA)\n",
    "USE_FACE_POINTS = True\n",
    "\n",
    "# https://github.com/tensorflow/tfjs-models/commit/838611c02f51159afdd77469ce67f0e26b7bbb23#diff-e5d31503f11c6bae62542ea89982152514b81906dff0b718e44708bcf22aa361\n",
    "# https://github.com/ManuelTS/augmentedFaceMeshIndices/blob/master/Left_Eye.jpg\n",
    "# https://github.com/google/mediapipe/blob/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png\n",
    "\n",
    "# No he repetido los puntos que tenian en comun ciertos arreglos, como los puntos faciales en los datos\n",
    "# obtenidos de los videos se encuentran primeros, estos indices se corresponden\n",
    "\n",
    "rightEyebrowUpper = [156, 70, 63, 105, 66, 107, 55, 193]\n",
    "rightEyebrowLower = [35, 124, 46, 53, 52, 65]\n",
    "\n",
    "leftEyebrowUpper  = [383, 300, 293, 334, 296, 336, 285, 417]\n",
    "leftEyebrowLower  = [265, 353, 276, 283, 282, 295]\n",
    "    \n",
    "lipsUpperOuter    = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291]\n",
    "lipsLowerOuter    = [146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "lipsUpperInner    = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308]\n",
    "lipsLowerInner    = [95, 88, 178, 87, 14, 317, 402, 318, 324]\n",
    "\n",
    "facePointsIndexes = rightEyebrowUpper + rightEyebrowLower + leftEyebrowUpper + leftEyebrowLower + lipsUpperOuter + lipsLowerOuter + lipsUpperInner + lipsLowerInner\n",
    "\n",
    "# print(\"Puntos de cara \"+str(len(facePointsIndexes)))\n",
    "# print(\"Puntos de Posicion \"+str(len(POSE_POINT_INDEXES)))\n",
    "\n",
    "def build_columns():\n",
    "    print('Frames: ' + str(AMOUNT_OF_FRAMES))\n",
    "    print('Usar puntos faciales: ' + str(USE_FACE_POINTS))\n",
    "    global frame_columns\n",
    "    frame_columns = []\n",
    "\n",
    "    for frame in range(AMOUNT_OF_FRAMES):\n",
    "        \n",
    "        if (USE_FACE_POINTS):\n",
    "            for index in range (len(facePointsIndexes)):\n",
    "                frame_columns.append(f'''fr_{frame}_face_p{index}_x''')\n",
    "                frame_columns.append(f'''fr_{frame}_face_p{index}_y''')\n",
    "        \n",
    "        for index in range (len(POSE_POINT_INDEXES)):\n",
    "            frame_columns.append(f'''fr_{frame}_pose_p{index}_x''')\n",
    "            frame_columns.append(f'''fr_{frame}_pose_p{index}_y''')\n",
    "\n",
    "        for index in range (LEFT_HAND_POINTS):\n",
    "            frame_columns.append(f'''fr_{frame}_left_hand_p{index}_x''')\n",
    "            frame_columns.append(f'''fr_{frame}_left_hand_p{index}_y''')\n",
    "\n",
    "        for index in range (RIGHT_HAND_POINTS):\n",
    "            frame_columns.append(f'''fr_{frame}_right_hand_p{index}_x''')\n",
    "            frame_columns.append(f'''fr_{frame}_right_hand_p{index}_y''')\n",
    "    frame_columns.append(\"sign\")\n",
    "    print('Cantidad de columnas: '+ str(len(frame_columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_validation(frame):\n",
    "    for i in range(len(frame)):\n",
    "        if (frame[i] > 1):\n",
    "            if (frame[i] > 2.8): \n",
    "                print(\"Valor que supera al 2.8: \"+ str(frame[i]))\n",
    "            frame[i] = 1\n",
    "    \n",
    "def getVideoKeypoints(sign_iteration, person, video):\n",
    "    frames = []\n",
    "\n",
    "    ''' El valor 201 corresponde a la longitud fija que se otorgó a todos los videos\n",
    "    ya sea que estos la cumplan o no. Al momento de armar el parquet \n",
    "    con todos los videos procesados, aquellos que no llegaban a esta longitud se\n",
    "    completaron con \"frames\" de valores 3 (valor que no debería existir en los datos \n",
    "    originales por la normalizacion que realiza MediaPipe)\n",
    "    El valor 50 proviene de la cantidad de videos para cada seña\n",
    "    \n",
    "    Bloque de Seña: la seña me indica el bloque, y como cada bloque está compuesto por 50videos por 201 filas cada 1, el salto de bloque me lo da el indice de la seña que se está procesando comenzando desde el 0.\n",
    "    Bloque de seña: 50*201*sign_index\n",
    "\n",
    "    Bloque de persona: cada persona filma 5 videos por seña y como tenemos 10 personas, para acceder a la correspondiente realizamos, 5 videos de la persona * 201 frames por cada video\n",
    "    Bloque de persona: indiceDePersona * 5 * 201\n",
    "\n",
    "    Bloque de video: Una vez que conocemos el Bloque de Seña y Bloque de persona queda posicionar el video. Cada video esta compuesto por 201 frames\n",
    "    Bloque de video: 201*indiceDeVideo\n",
    "    '''\n",
    "    for frameIndex in range(201):\n",
    "        frame = []\n",
    "        frame = dataframe.iloc[ (50*201*sign_iteration)+(person*5*201)+(201*video) + frameIndex ].to_list()\n",
    "        # quito ultima columna con la seña de cada frame/fila\n",
    "        frame.pop()\n",
    "\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def store_dataset(dataset, name):\n",
    "    dataset.to_parquet('./01_criterios/{0}.parquet'.format(name))\n",
    "    print('Se almacenó: ./01_criterios/{0}.parquet'.format(name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUESTREO PODA\n",
    "Se realiza una poda de los frames iniciales y finales de cada video. Para ello se calculará el 15% de la cantidad de frames para cada video y este valor (cantidad de frames) no serán tenidas en cuenta. Por ejemplo, si el valor es de 10, no se tomarán en cuenta los primeros 10 y ultimos 10 frames (como si estos hubieran sido podados). Luego se tomará de forma aleatoria los frames restantes para el aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    dataFrameRows = []\n",
    "\n",
    "    # sign_iteration se utiliza para poder acceder a los bloques de la seña correspondiente\n",
    "    # por ejemplo la seña 'Brillante' se encontrará primera en el parquet pero con la lista de señas no es posible conocer su posicion en el parquet\n",
    "    # debido a esto se utiliza esta variable\n",
    "    sign_iteration = 0\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    for sign in range(len(FULL_SIGNS_LIST)):\n",
    "        if (SIGNS_LIST.count(FULL_SIGNS_LIST[sign])):\n",
    "            for j in range(10):\n",
    "                for k in range(5):\n",
    "                    cap = cv2.VideoCapture(f'''C:/Users/facur/Desktop/tesis_LSA/codigos_datos_tesis/LSA64/all_cut/0{str(sign+1).zfill(2)}_0{str(j+1).zfill(2)}_00{k+1}.mp4''')\n",
    "                    framesLength = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "                    fifth_percent = int(framesLength*0.15)\n",
    "\n",
    "                    video_keypoints = getVideoKeypoints(sign_iteration = sign_iteration, person = j, video = k)\n",
    "\n",
    "                    randomFrames = []\n",
    "                    \n",
    "                    # si podando tenemos frames para completar todo, es decir,\n",
    "                    # luego de la poda la cantidad de frames es mayor o igual a la cantidad de frames con la que queremos trabajar <AMOUNT_OF_FRAMES> \n",
    "                    # El factor *2 se realiza ya que la poda es del inicio y del final\n",
    "                    if (framesLength - (fifth_percent*2) > AMOUNT_OF_FRAMES): \n",
    "                        for i in range(AMOUNT_OF_FRAMES):\n",
    "                            number = random.randint(fifth_percent, framesLength - fifth_percent)\n",
    "                            while(randomFrames.count(number)):\n",
    "                                number = random.randint(fifth_percent, framesLength - fifth_percent)\n",
    "                            randomFrames.append(number)\n",
    "                    else:\n",
    "                        # como el video con menor cantidad de frames es 14, este bloque \"poda\" como minimo los primeros 2 y ultimos 2 frames. \n",
    "                        # Y poda con valores superiores en aquellos casos donde la cantidad de frames luego de la poda inicial y final no lleguen a la cantidad de <AMOUNT_OF_FRAMES> frames\n",
    "                        frames_to_jump = math.floor((framesLength - AMOUNT_OF_FRAMES) / 2)\n",
    "                        for i in range(AMOUNT_OF_FRAMES):\n",
    "                            number = random.randint(frames_to_jump, framesLength - frames_to_jump)\n",
    "                            while(randomFrames.count(number)):\n",
    "                                number = random.randint(frames_to_jump, framesLength - frames_to_jump)\n",
    "                            randomFrames.append(number)\n",
    "                        \n",
    "                    randomFrames.sort()\n",
    "\n",
    "                    if (framesLength == 14):\n",
    "                        print(randomFrames)\n",
    "                        print(fifth_percent)\n",
    "                    \n",
    "                    aux_array = []\n",
    "                    for randomFrame in randomFrames:\n",
    "                        values_validation(video_keypoints[randomFrame])\n",
    "                        if (USE_FACE_POINTS):\n",
    "                            for faceKeypoint in facePointsIndexes:\n",
    "                                aux_array.append(video_keypoints[randomFrame][faceKeypoint*2])     # X\n",
    "                                aux_array.append(video_keypoints[randomFrame][faceKeypoint*2+1])   # Y\n",
    "                        # POSE\n",
    "                        for poseKeypoint in range(936, 936+len(POSE_POINT_INDEXES)*2):\n",
    "                            aux_array.append(video_keypoints[randomFrame][poseKeypoint])\n",
    "                        for keypoint in range(1002, 1086):\n",
    "                            aux_array.append(video_keypoints[randomFrame][keypoint])\n",
    "                    aux_array.append(FULL_SIGNS_LIST[sign])\n",
    "\n",
    "                    dataFrameRows.append(aux_array)\n",
    "            sign_iteration = sign_iteration + 1\n",
    "                \n",
    "    return pd.DataFrame(dataFrameRows,columns=frame_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extended_dataset():\n",
    "    dataFrameRows = []\n",
    "\n",
    "    # sign_iteration se utiliza para poder acceder a los bloques de la seña correspondiente\n",
    "    # por ejemplo la seña 'Brillante' se encontrará primera en el parquet pero con la lista de señas no es posible conocer su posicion en el parquet\n",
    "    # debido a esto se utiliza esta variable\n",
    "    sign_iteration = 0\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    for sign in range(len(FULL_SIGNS_LIST)):\n",
    "        if (SIGNS_LIST.count(FULL_SIGNS_LIST[sign])):\n",
    "            for j in range(10):\n",
    "                for k in range(5):\n",
    "                    cap = cv2.VideoCapture(f'''C:/Users/facur/Desktop/tesis_LSA/codigos_datos_tesis/LSA64/all_cut/0{str(sign+1).zfill(2)}_0{str(j+1).zfill(2)}_00{k+1}.mp4''')\n",
    "                    framesLength = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "                    fifth_percent = int(framesLength*0.15)\n",
    "\n",
    "                    video_keypoints = getVideoKeypoints(sign_iteration = sign_iteration, person = j, video = k)\n",
    "\n",
    "                    randomFrames = []\n",
    "                \n",
    "                    if (framesLength - (fifth_percent*2) > AMOUNT_OF_FRAMES): #si podando tenemos frames para completar todo, *2 ya que es poda del inicio y del final\n",
    "                        for i in range(AMOUNT_OF_FRAMES):\n",
    "                            number = random.randint(fifth_percent, framesLength - fifth_percent)\n",
    "                            while(randomFrames.count(number)):\n",
    "                                number = random.randint(fifth_percent, framesLength - fifth_percent)\n",
    "                            randomFrames.append(number)\n",
    "                    else:\n",
    "                        # repito frames aleatorios para completar la cantidad requerida de frames\n",
    "                        for number in range(AMOUNT_OF_FRAMES):\n",
    "                            # se itera desde 0 hasta la cantidad de Frames Objetivo que tenemos, por ejemplo queremos armar un set de datos\n",
    "                            # con 30 frames, pero el video cuenta con 14 frames, en ese caso, se itera desde 0 a 30 calculando el modulo\n",
    "                            # entre la iteracion actual y la cantidad de frames del video (14), y así se evita acceder a frames inexistentes\n",
    "                            randomFrames.append(number % framesLength)\n",
    "                \n",
    "                    randomFrames.sort()\n",
    "                    \n",
    "                    aux_array = []\n",
    "                    for randomFrame in randomFrames:\n",
    "                        values_validation(video_keypoints[randomFrame])\n",
    "                        if (USE_FACE_POINTS):\n",
    "                            for faceKeypoint in facePointsIndexes:\n",
    "                                aux_array.append(video_keypoints[randomFrame][faceKeypoint*2])     # X\n",
    "                                aux_array.append(video_keypoints[randomFrame][faceKeypoint*2+1])   # Y\n",
    "                        # POSE\n",
    "                        for poseKeypoint in range(936, 936+len(POSE_POINT_INDEXES)*2):\n",
    "                            aux_array.append(video_keypoints[randomFrame][poseKeypoint])\n",
    "                        for keypoint in range(1002, 1086):\n",
    "                            aux_array.append(video_keypoints[randomFrame][keypoint])\n",
    "                    aux_array.append(FULL_SIGNS_LIST[sign])\n",
    "\n",
    "                    dataFrameRows.append(aux_array)\n",
    "            sign_iteration = sign_iteration + 1\n",
    "                \n",
    "    return pd.DataFrame(dataFrameRows,columns=frame_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE PROCEDE A CONSTRUIR LOS DISTINTOS DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames: 10\n",
      "Usar puntos faciales: False\n",
      "Cantidad de columnas: 1301\n",
      "[2, 3, 4, 5, 7, 8, 9, 10, 11, 12]\n",
      "2\n",
      "Nro de Filas: 1050\n",
      "Nro de Columnas: 1301\n",
      "Se almacenó: ./01_criterios/criterio_random_10fr_no_face.parquet\n",
      "Frames: 10\n",
      "Usar puntos faciales: True\n",
      "Cantidad de columnas: 2661\n",
      "[2, 3, 4, 5, 7, 8, 9, 10, 11, 12]\n",
      "2\n",
      "Nro de Filas: 1050\n",
      "Nro de Columnas: 2661\n",
      "Se almacenó: ./01_criterios/criterio_random_10fr_with_face.parquet\n",
      "Frames: 30\n",
      "Usar puntos faciales: False\n",
      "Cantidad de columnas: 3901\n",
      "Nro de Filas: 1050\n",
      "Nro de Columnas: 3901\n",
      "Se almacenó: ./01_criterios/criterio_random_30fr_no_face.parquet\n",
      "Frames: 30\n",
      "Usar puntos faciales: True\n",
      "Cantidad de columnas: 7981\n",
      "Nro de Filas: 1050\n",
      "Nro de Columnas: 7981\n",
      "Se almacenó: ./01_criterios/criterio_random_30fr_with_face.parquet\n"
     ]
    }
   ],
   "source": [
    "# -------------- DATASET muestreo 10 frames SIN cara\n",
    "AMOUNT_OF_FRAMES = 10\n",
    "USE_FACE_POINTS = False\n",
    "\n",
    "build_columns()\n",
    "dataset = build_dataset()\n",
    "print('Nro de Filas: '+str(len(dataset.axes[0])))\n",
    "print('Nro de Columnas: '+str(len(dataset.axes[1])))\n",
    "# print(dataset.head())\n",
    "store_dataset(dataset, 'criterio_poda_10fr_no_face')\n",
    "\n",
    "# -------------- DATASET muestreo 10 frames CON cara\n",
    "AMOUNT_OF_FRAMES = 10\n",
    "USE_FACE_POINTS = True\n",
    "\n",
    "build_columns()\n",
    "dataset = build_dataset()\n",
    "print('Nro de Filas: '+str(len(dataset.axes[0])))\n",
    "print('Nro de Columnas: '+str(len(dataset.axes[1])))\n",
    "# print(dataset.head())\n",
    "store_dataset(dataset, 'criterio_poda_10fr_with_face')\n",
    "\n",
    "# -------------- DATASET muestreo 30 frames SIN cara\n",
    "AMOUNT_OF_FRAMES = 30\n",
    "USE_FACE_POINTS = False\n",
    "\n",
    "build_columns()\n",
    "dataset = build_extended_dataset()\n",
    "print('Nro de Filas: '+str(len(dataset.axes[0])))\n",
    "print('Nro de Columnas: '+str(len(dataset.axes[1])))\n",
    "# print(dataset.head())\n",
    "store_dataset(dataset, 'criterio_poda_30fr_no_face')\n",
    "\n",
    "# -------------- DATASET muestreo 30 frames CON cara\n",
    "AMOUNT_OF_FRAMES = 30\n",
    "USE_FACE_POINTS = True\n",
    "\n",
    "build_columns()\n",
    "dataset = build_extended_dataset()\n",
    "print('Nro de Filas: '+str(len(dataset.axes[0])))\n",
    "print('Nro de Columnas: '+str(len(dataset.axes[1])))\n",
    "# print(dataset.head())\n",
    "store_dataset(dataset, 'criterio_poda_30fr_with_face')\n",
    "\n",
    "del dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
